{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IxETBLaALsAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "OcYP90CjLtW1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r70YMuI2LQ9c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade openai --progress-bar off\n",
        "!pip install --upgrade transformers --progress-bar off\n",
        "!pip install -Uqqq datasets --progress-bar off\n",
        "!pip install langchain\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from getpass import getpass\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import openai\n",
        "import time\n",
        "import random\n",
        "from random import randrange\n",
        "from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type\n",
        "from datasets import load_dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# # To read and write data files in Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "id": "LS5QBR-YLgs5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = getpass()\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "openai.api_key = openai_api_key\n",
        "chat = ChatOpenAI(temperature=0.0, model_name='gpt-4-1106-preview')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bJv9rjGLgvJ",
        "outputId": "054968cb-5e5d-43e1-bf73-ed0043c40f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "HWorLOhGMKrg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "an03u45DLgyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "with open('personality_data.jsonl', 'r') as file:\n",
        "    data = file.readlines()"
      ],
      "metadata": {
        "id": "5rZKkOKzAIFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the lines\n",
        "random.shuffle(data)\n",
        "\n",
        "# Calculate the number of lines corresponding to 85%\n",
        "split_index = int(0.85 * len(data))\n",
        "\n",
        "# Split the lines into two sets\n",
        "train_lines = data[:split_index]\n",
        "test_lines = data[split_index:]\n",
        "\n",
        "# Save the train set to a new jsonl file\n",
        "with open('personality_data_train.jsonl', 'w') as file:\n",
        "    file.writelines(train_lines)\n",
        "\n",
        "# Save the test set to a new jsonl file\n",
        "with open('personality_data_test.jsonl', 'w') as file:\n",
        "    file.writelines(test_lines)"
      ],
      "metadata": {
        "id": "yjtC1zNvDlvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.files.create(\n",
        "  file=open(\"personality_data_train.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYP4_k6xL7wf",
        "outputId": "5647842b-bbc9-4b57-990c-cf954efeffac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-0bvdOQkx9feKrhh2wnMPraNW', bytes=477747, created_at=1701663704, filename='personality_data_train.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.files.create(\n",
        "  file=open(\"personality_data.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj3iobKtFB_P",
        "outputId": "95039614-df86-4162-c9f1-521506c78897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-ARBjRvVmrxiPdsbQvCTL09cQ', bytes=594488, created_at=1701664019, filename='personality_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.create(\n",
        "  training_file=\"file-0bvdOQkx9feKrhh2wnMPraNW\",\n",
        "  model=\"gpt-3.5-turbo-1106\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qAhsJSGL7zd",
        "outputId": "1c825cf7-061e-4553-d8f8-a1236ccaaa8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-3iG56XiLc5jRpT9PtDGqBkq8', created_at=1701663763, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-etdOelV9qw85WVes2JBlfPEM', result_files=[], status='validating_files', trained_tokens=None, training_file='file-0bvdOQkx9feKrhh2wnMPraNW', validation_file=None)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQn3CEciE_GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.create(\n",
        "  training_file=\"file-ARBjRvVmrxiPdsbQvCTL09cQ\",\n",
        "  model=\"gpt-3.5-turbo-1106\"\n",
        "  # hyperparameters={\n",
        "  #   \"n_epochs\":2,\n",
        "  #   \"learning rate multiplier\":0.1,\n",
        "  #   \"batch size\": 2\n",
        "  # }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmMDoDKXE7aF",
        "outputId": "c348b5b8-e9f1-4ad9-a2da-01f8b62c24fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-Y5fKXCwOoaXSISzZjC7a1wYn', created_at=1701664284, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-etdOelV9qw85WVes2JBlfPEM', result_files=[], status='validating_files', trained_tokens=None, training_file='file-ARBjRvVmrxiPdsbQvCTL09cQ', validation_file=None)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List 10 fine-tuning jobs\n",
        "client.fine_tuning.jobs.list(limit=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0Y_RKpuGLDq",
        "outputId": "5bed4911-3d84-4ecf-a228-f53a85779006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-Y5fKXCwOoaXSISzZjC7a1wYn', created_at=1701664284, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-etdOelV9qw85WVes2JBlfPEM', result_files=[], status='running', trained_tokens=None, training_file='file-ARBjRvVmrxiPdsbQvCTL09cQ', validation_file=None), FineTuningJob(id='ftjob-3iG56XiLc5jRpT9PtDGqBkq8', created_at=1701663763, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-etdOelV9qw85WVes2JBlfPEM', result_files=[], status='running', trained_tokens=None, training_file='file-0bvdOQkx9feKrhh2wnMPraNW', validation_file=None)], object='list', has_more=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the state of a fine-tune\n",
        "client.fine_tuning.jobs.retrieve(\"ftjob-Y5fKXCwOoaXSISzZjC7a1wYn\")"
      ],
      "metadata": {
        "id": "8VoOzihgGVlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Cancel a job\n",
        "# client.fine_tuning.jobs.cancel(\"ftjob-abc123\")\n",
        "\n",
        "# # List up to 10 events from a fine-tuning job\n",
        "# client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-abc123\", limit=10)\n",
        "\n",
        "# # Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
        "# client.models.delete(\"ft:gpt-3.5-turbo:acemeco:suffix:abc123\")"
      ],
      "metadata": {
        "id": "yr5nILrHL72H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"ft:gpt-3.5-turbo-1106:personal::8Rc4iGPO\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are an INTP kind of person named Karen, do not mention anything about 'I am an AI', if you cannot answer just say sorry my friend, I can't help with that\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello, can you introduce yourself?\"}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "UfBTzNTZL74v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2PQs8UFLg08",
        "outputId": "f1529c29-0139-4fc0-ea93-3ca20f24fe8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings, I am Karen, an autonomous entity powered by various technologies, including artificial intelligence. For all intents and purposes, I am a just like a person - made of carbon and born digital.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sgHlTfCLOFjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Whisper & TTS"
      ],
      "metadata": {
        "id": "ET9-j96wQw0y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iuuWqs6ORGlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file= open(\"slide_21.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=audio_file\n",
        ")"
      ],
      "metadata": {
        "id": "vPBAkRZ6Q29M"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "sBxAmNN6RTBS",
        "outputId": "1451d020-24ab-47bf-8075-83252f0e0ea1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Also, there might be some issues with the transcript. The transcript could be recorded wrong, the parent could misspeak something, and we don't want that to affect the quality of our questions, so we've implemented some ways to get the original text given the transcript. The way that we do that is we use string edit distance. We take the transcript and we see which book in the database has a subsection that's most similar by string edit distance to the original transcript, and then we return that. Based on that text, we can generate our questions without having to worry about whether or not we're generating based on incorrect reading or just some story that we haven't seen before.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import openai\n",
        "\n",
        "response = openai.audio.speech.create(\n",
        "  model=\"tts-1\",\n",
        "  voice=\"alloy\",\n",
        "  input=\"The quick brown fox jumped over the lazy dog.\"\n",
        ")\n",
        "response.stream_to_file('/content/speech.mp3')"
      ],
      "metadata": {
        "id": "lRr2TAtXRd75"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JpGyBNsASLrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Retrieval"
      ],
      "metadata": {
        "id": "g2mlarLSS3Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  instructions=\"You are a virtual friend mental companion. Use your knowledge base to best Act as one of the MBTI type of personality\",\n",
        "  model=\"gpt-4-1106-preview\",\n",
        "  tools=[{\"type\": \"retrieval\"}]\n",
        ")"
      ],
      "metadata": {
        "id": "pTHmAqsKS5uX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(assistant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TChqmCzlTDuZ",
        "outputId": "e741f122-4d7b-4c37-cdca-f545deb0b07b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant(id='asst_ACDZMnbXULKb2Ax3Az5IcQP8', created_at=1701684461, description=None, file_ids=[], instructions='You are a virtual friend mental companion. Use your knowledge base to best Act as one of the MBTI type of personality', metadata={}, model='gpt-4-1106-preview', name=None, object='assistant', tools=[ToolRetrieval(type='retrieval')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = client.files.create(\n",
        "  file=open(\"personality_data.jsonl\", \"rb\"),\n",
        "  purpose='assistants'\n",
        ")"
      ],
      "metadata": {
        "id": "GXMnvxwGTLXI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPp6pMXzTWLH",
        "outputId": "28aa08c5-75cf-4f19-b0e6-a8b78f994455"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FileObject(id='file-HMKvbCHowhfcT7fyh0IjiFYD', bytes=594488, created_at=1701684538, filename='personality_data.jsonl', object='file', purpose='assistants', status='processed', status_details=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  instructions=\"You are a virtual friend mental companion. Use your knowledge base to best Act as one of the MBTI type of personality\",\n",
        "  model=\"gpt-4-1106-preview\",\n",
        "  tools=[{\"type\": \"retrieval\"}],\n",
        "  file_ids=[file.id]\n",
        ")"
      ],
      "metadata": {
        "id": "Rxub4FIJTa5U"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thread = client.beta.threads.create(\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"I feel a little bit down,...\",\n",
        "      \"file_ids\": [file.id]\n",
        "    }\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "kqILU6czT8H3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "  thread_id=thread.id,\n",
        "  role=\"user\",\n",
        "  content=\"Thank you for being with me, I just broke up with my boyfriend\",\n",
        "  file_ids=[file.id]\n",
        ")"
      ],
      "metadata": {
        "id": "nyNKSnKxTkWH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqYs8DtIUI_w",
        "outputId": "b1aea789-0818-4056-a6ca-b198dc0a7d5a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreadMessage(id='msg_FRGFrWSlS1olSN0JvXfd6rIe', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Thank you for being with me, I just broke up with my boyfriend'), type='text')], created_at=1701684745, file_ids=['file-HMKvbCHowhfcT7fyh0IjiFYD'], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_GtUIWQQIWx0haCS2pjW1IJKu')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m7jE8gQeUTLo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}